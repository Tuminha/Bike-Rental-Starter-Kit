{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üìä Bike Rental Analytics - Phase 5: Analytics Views\n",
        "\n",
        "## Project Overview\n",
        "This notebook focuses on creating SQL views for business intelligence and analytics, enabling the bike rental company to understand weather impact on ridership patterns.\n",
        "\n",
        "## Phase 5 Objectives\n",
        "- Create weather-ridership correlation views\n",
        "- Build time-based aggregations (hourly/daily/weekly)\n",
        "- Design station utilization analytics\n",
        "- Implement KPI views (ride counts, duration stats)\n",
        "- Document view purposes and usage\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üì¶ Setup and Database Connection\n",
        "\n",
        "Let's connect to our database and set up for creating analytics views.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Database connection established!\n",
            "üìä Connected to: bike_rental_db on localhost\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries and connect to database\n",
        "import pandas as pd\n",
        "import psycopg2\n",
        "from sqlalchemy import create_engine\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Database connection parameters (same as Phase 4)\n",
        "db_params = {\n",
        "    'host': 'localhost',\n",
        "    'database': 'bike_rental_db',\n",
        "    'user': 'franciscoteixeirabarbosa',\n",
        "    'password': '',\n",
        "    'port': 5432\n",
        "}\n",
        "\n",
        "# Create connection string\n",
        "conn_string = f\"host={db_params['host']} dbname={db_params['database']} user={db_params['user']} port={db_params['port']}\"\n",
        "\n",
        "# Create SQLAlchemy engine\n",
        "engine = create_engine(f\"postgresql://{db_params['user']}@{db_params['host']}:{db_params['port']}/{db_params['database']}\")\n",
        "\n",
        "print(\"‚úÖ Database connection established!\")\n",
        "print(f\"üìä Connected to: {db_params['database']} on {db_params['host']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üå§Ô∏è Weather-Ridership Correlation Views\n",
        "\n",
        "Let's create views that combine weather data with ridership patterns to understand correlations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Created daily_weather_rides view successfully!\n",
            "üìä Sample data from daily_weather_rides view:\n",
            "   2016-01-01: 41¬∞F, 163 rides, 28 stations\n",
            "   2016-01-02: 36¬∞F, 206 rides, 29 stations\n",
            "   2016-01-03: 37¬∞F, 276 rides, 30 stations\n",
            "   2016-01-04: 32¬∞F, 286 rides, 29 stations\n",
            "   2016-01-05: 19¬∞F, 273 rides, 30 stations\n"
          ]
        }
      ],
      "source": [
        "# Create daily weather-ridership correlation view\n",
        "try:\n",
        "    conn = psycopg2.connect(conn_string)\n",
        "    cursor = conn.cursor()\n",
        "    \n",
        "    # Create view for daily weather and ridership correlation\n",
        "    create_daily_weather_rides_view = \"\"\"\n",
        "    CREATE OR REPLACE VIEW daily_weather_rides AS\n",
        "    SELECT \n",
        "        w.date,\n",
        "        w.avg_temp,\n",
        "        w.max_temp,\n",
        "        w.min_temp,\n",
        "        w.precipitation,\n",
        "        w.avg_wind_speed,\n",
        "        w.weather_category,\n",
        "        w.season,\n",
        "        COUNT(r.ride_id) as total_rides,\n",
        "        COUNT(DISTINCT r.start_station_id) as active_stations,\n",
        "        ROUND(AVG(r.trip_duration_minutes), 2) as avg_trip_duration,\n",
        "        ROUND(AVG(r.age), 1) as avg_rider_age,\n",
        "        COUNT(CASE WHEN r.user_type = 'Subscriber' THEN 1 END) as subscriber_rides,\n",
        "        COUNT(CASE WHEN r.user_type = 'Customer' THEN 1 END) as customer_rides,\n",
        "        ROUND(COUNT(CASE WHEN r.user_type = 'Subscriber' THEN 1 END) * 100.0 / COUNT(r.ride_id), 1) as subscriber_percentage\n",
        "    FROM weather w\n",
        "    LEFT JOIN rides r ON w.date = r.date\n",
        "    GROUP BY w.date, w.avg_temp, w.max_temp, w.min_temp, w.precipitation, \n",
        "             w.avg_wind_speed, w.weather_category, w.season\n",
        "    ORDER BY w.date;\n",
        "    \"\"\"\n",
        "    \n",
        "    cursor.execute(create_daily_weather_rides_view)\n",
        "    conn.commit()\n",
        "    \n",
        "    print(\"‚úÖ Created daily_weather_rides view successfully!\")\n",
        "    \n",
        "    # Test the view\n",
        "    cursor.execute(\"SELECT * FROM daily_weather_rides LIMIT 5;\")\n",
        "    sample_data = cursor.fetchall()\n",
        "    \n",
        "    print(\"üìä Sample data from daily_weather_rides view:\")\n",
        "    for row in sample_data:\n",
        "        print(f\"   {row[0]}: {row[1]}¬∞F, {row[8]} rides, {row[9]} stations\")\n",
        "    \n",
        "    cursor.close()\n",
        "    conn.close()\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error creating daily weather-rides view: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚è∞ Time-Based Analytics Views\n",
        "\n",
        "Let's create views for analyzing ridership patterns by time (hourly, daily, weekly).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Created hourly_ridership_patterns view successfully!\n",
            "üìä Peak hours by ridership:\n",
            "   08:00: 29241 rides (11.83% of daily)\n",
            "   18:00: 24452 rides (9.90% of daily)\n",
            "   17:00: 22049 rides (8.92% of daily)\n",
            "   19:00: 18293 rides (7.40% of daily)\n",
            "   07:00: 16818 rides (6.81% of daily)\n"
          ]
        }
      ],
      "source": [
        "# Create hourly ridership patterns view\n",
        "try:\n",
        "    conn = psycopg2.connect(conn_string)\n",
        "    cursor = conn.cursor()\n",
        "    \n",
        "    # Create view for hourly ridership patterns\n",
        "    create_hourly_patterns_view = \"\"\"\n",
        "    CREATE OR REPLACE VIEW hourly_ridership_patterns AS\n",
        "    SELECT \n",
        "        hour_of_day,\n",
        "        COUNT(*) as total_rides,\n",
        "        ROUND(AVG(trip_duration_minutes), 2) as avg_trip_duration,\n",
        "        COUNT(CASE WHEN user_type = 'Subscriber' THEN 1 END) as subscriber_rides,\n",
        "        COUNT(CASE WHEN user_type = 'Customer' THEN 1 END) as customer_rides,\n",
        "        ROUND(AVG(age), 1) as avg_rider_age,\n",
        "        COUNT(DISTINCT start_station_id) as active_stations,\n",
        "        ROUND(COUNT(*) * 100.0 / SUM(COUNT(*)) OVER(), 2) as percentage_of_daily_rides\n",
        "    FROM rides\n",
        "    WHERE hour_of_day IS NOT NULL\n",
        "    GROUP BY hour_of_day\n",
        "    ORDER BY hour_of_day;\n",
        "    \"\"\"\n",
        "    \n",
        "    cursor.execute(create_hourly_patterns_view)\n",
        "    conn.commit()\n",
        "    \n",
        "    print(\"‚úÖ Created hourly_ridership_patterns view successfully!\")\n",
        "    \n",
        "    # Test the view\n",
        "    cursor.execute(\"SELECT * FROM hourly_ridership_patterns ORDER BY total_rides DESC LIMIT 5;\")\n",
        "    peak_hours = cursor.fetchall()\n",
        "    \n",
        "    print(\"üìä Peak hours by ridership:\")\n",
        "    for row in peak_hours:\n",
        "        print(f\"   {row[0]:02d}:00: {row[1]} rides ({row[7]}% of daily)\")\n",
        "    \n",
        "    cursor.close()\n",
        "    conn.close()\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error creating hourly patterns view: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Created weekly_ridership_patterns view successfully!\n",
            "üìä Weekly ridership patterns:\n",
            "   Wednesday: 40517 rides (16.40% of weekly)\n",
            "   Thursday: 39513 rides (15.99% of weekly)\n",
            "   Tuesday: 38751 rides (15.68% of weekly)\n",
            "   Friday: 37205 rides (15.06% of weekly)\n",
            "   Monday: 36296 rides (14.69% of weekly)\n",
            "   Saturday: 27843 rides (11.27% of weekly)\n",
            "   Sunday: 26986 rides (10.92% of weekly)\n"
          ]
        }
      ],
      "source": [
        "# Create weekly ridership patterns view\n",
        "try:\n",
        "    conn = psycopg2.connect(conn_string)\n",
        "    cursor = conn.cursor()\n",
        "    \n",
        "    # Create view for weekly ridership patterns\n",
        "    create_weekly_patterns_view = \"\"\"\n",
        "    CREATE OR REPLACE VIEW weekly_ridership_patterns AS\n",
        "    SELECT \n",
        "        CASE day_of_week\n",
        "            WHEN 0 THEN 'Monday'\n",
        "            WHEN 1 THEN 'Tuesday'\n",
        "            WHEN 2 THEN 'Wednesday'\n",
        "            WHEN 3 THEN 'Thursday'\n",
        "            WHEN 4 THEN 'Friday'\n",
        "            WHEN 5 THEN 'Saturday'\n",
        "            WHEN 6 THEN 'Sunday'\n",
        "        END as day_name,\n",
        "        day_of_week,\n",
        "        COUNT(*) as total_rides,\n",
        "        ROUND(AVG(trip_duration_minutes), 2) as avg_trip_duration,\n",
        "        COUNT(CASE WHEN user_type = 'Subscriber' THEN 1 END) as subscriber_rides,\n",
        "        COUNT(CASE WHEN user_type = 'Customer' THEN 1 END) as customer_rides,\n",
        "        ROUND(AVG(age), 1) as avg_rider_age,\n",
        "        COUNT(DISTINCT start_station_id) as active_stations,\n",
        "        ROUND(COUNT(*) * 100.0 / SUM(COUNT(*)) OVER(), 2) as percentage_of_weekly_rides\n",
        "    FROM rides\n",
        "    WHERE day_of_week IS NOT NULL\n",
        "    GROUP BY day_of_week\n",
        "    ORDER BY day_of_week;\n",
        "    \"\"\"\n",
        "    \n",
        "    cursor.execute(create_weekly_patterns_view)\n",
        "    conn.commit()\n",
        "    \n",
        "    print(\"‚úÖ Created weekly_ridership_patterns view successfully!\")\n",
        "    \n",
        "    # Test the view\n",
        "    cursor.execute(\"SELECT * FROM weekly_ridership_patterns ORDER BY total_rides DESC;\")\n",
        "    weekly_data = cursor.fetchall()\n",
        "    \n",
        "    print(\"üìä Weekly ridership patterns:\")\n",
        "    for row in weekly_data:\n",
        "        print(f\"   {row[0]}: {row[2]} rides ({row[8]}% of weekly)\")\n",
        "    \n",
        "    cursor.close()\n",
        "    conn.close()\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error creating weekly patterns view: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üè™ Station Utilization Analytics\n",
        "\n",
        "Let's create views for analyzing station performance and utilization patterns.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Created station_utilization view successfully!\n",
            "üìä Top 5 stations by utilization:\n",
            "   Grove St PATH: 66361 total rides, 183.0 rides/day\n",
            "   Exchange Place: 40252 total rides, 111.0 rides/day\n",
            "   Sip Ave: 32675 total rides, 90.0 rides/day\n",
            "   Hamilton Park: 29876 total rides, 82.0 rides/day\n",
            "   Newport PATH: 26187 total rides, 72.0 rides/day\n"
          ]
        }
      ],
      "source": [
        "# Create station utilization view\n",
        "try:\n",
        "    conn = psycopg2.connect(conn_string)\n",
        "    cursor = conn.cursor()\n",
        "    \n",
        "    # Create view for station utilization analytics\n",
        "    create_station_utilization_view = \"\"\"\n",
        "    CREATE OR REPLACE VIEW station_utilization AS\n",
        "    SELECT \n",
        "        s.station_id,\n",
        "        s.station_name,\n",
        "        s.latitude,\n",
        "        s.longitude,\n",
        "        COUNT(r.ride_id) as total_rides,\n",
        "        COUNT(CASE WHEN r.start_station_id = s.station_id THEN 1 END) as rides_started,\n",
        "        COUNT(CASE WHEN r.end_station_id = s.station_id THEN 1 END) as rides_ended,\n",
        "        ROUND(AVG(r.trip_duration_minutes), 2) as avg_trip_duration,\n",
        "        COUNT(DISTINCT r.date) as active_days,\n",
        "        ROUND(COUNT(r.ride_id) * 100.0 / SUM(COUNT(r.ride_id)) OVER(), 2) as percentage_of_total_rides,\n",
        "        ROUND(COUNT(r.ride_id) / COUNT(DISTINCT r.date), 1) as avg_rides_per_day\n",
        "    FROM stations s\n",
        "    LEFT JOIN rides r ON (s.station_id = r.start_station_id OR s.station_id = r.end_station_id)\n",
        "    GROUP BY s.station_id, s.station_name, s.latitude, s.longitude\n",
        "    ORDER BY total_rides DESC;\n",
        "    \"\"\"\n",
        "    \n",
        "    cursor.execute(create_station_utilization_view)\n",
        "    conn.commit()\n",
        "    \n",
        "    print(\"‚úÖ Created station_utilization view successfully!\")\n",
        "    \n",
        "    # Test the view\n",
        "    cursor.execute(\"SELECT * FROM station_utilization LIMIT 5;\")\n",
        "    top_stations = cursor.fetchall()\n",
        "    \n",
        "    print(\"üìä Top 5 stations by utilization:\")\n",
        "    for row in top_stations:\n",
        "        print(f\"   {row[1]}: {row[4]} total rides, {row[10]} rides/day\")\n",
        "    \n",
        "    cursor.close()\n",
        "    conn.close()\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error creating station utilization view: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìà KPI and Business Intelligence Views\n",
        "\n",
        "Let's create views for key performance indicators and business insights.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Created monthly_kpi_summary view successfully!\n",
            "üìä Top 3 months by ridership:\n",
            "   August    2016: 34083 rides, 92.1% subscribers, 79.5¬∞F avg\n",
            "   September 2016: 33284 rides, 94.2% subscribers, 72.3¬∞F avg\n",
            "   October   2016: 29553 rides, 96.4% subscribers, 59.6¬∞F avg\n"
          ]
        }
      ],
      "source": [
        "# Create monthly KPI summary view\n",
        "try:\n",
        "    conn = psycopg2.connect(conn_string)\n",
        "    cursor = conn.cursor()\n",
        "    \n",
        "    # Create view for monthly KPI summary\n",
        "    create_monthly_kpi_view = \"\"\"\n",
        "    CREATE OR REPLACE VIEW monthly_kpi_summary AS\n",
        "    SELECT \n",
        "        EXTRACT(YEAR FROM r.date) as year,\n",
        "        EXTRACT(MONTH FROM r.date) as month,\n",
        "        TO_CHAR(r.date, 'Month') as month_name,\n",
        "        COUNT(r.ride_id) as total_rides,\n",
        "        COUNT(DISTINCT r.start_station_id) as active_stations,\n",
        "        COUNT(DISTINCT r.bike_id) as bikes_used,\n",
        "        ROUND(AVG(r.trip_duration_minutes), 2) as avg_trip_duration,\n",
        "        ROUND(AVG(r.age), 1) as avg_rider_age,\n",
        "        COUNT(CASE WHEN r.user_type = 'Subscriber' THEN 1 END) as subscriber_rides,\n",
        "        COUNT(CASE WHEN r.user_type = 'Customer' THEN 1 END) as customer_rides,\n",
        "        ROUND(COUNT(CASE WHEN r.user_type = 'Subscriber' THEN 1 END) * 100.0 / COUNT(r.ride_id), 1) as subscriber_percentage,\n",
        "        ROUND(AVG(w.avg_temp), 1) as avg_temperature,\n",
        "        ROUND(SUM(w.precipitation), 2) as total_precipitation,\n",
        "        COUNT(CASE WHEN w.weather_category = 'Hot' THEN 1 END) as hot_days,\n",
        "        COUNT(CASE WHEN w.weather_category = 'Cold' THEN 1 END) as cold_days\n",
        "    FROM rides r\n",
        "    JOIN weather w ON r.date = w.date\n",
        "    GROUP BY EXTRACT(YEAR FROM r.date), EXTRACT(MONTH FROM r.date), TO_CHAR(r.date, 'Month')\n",
        "    ORDER BY year, month;\n",
        "    \"\"\"\n",
        "    \n",
        "    cursor.execute(create_monthly_kpi_view)\n",
        "    conn.commit()\n",
        "    \n",
        "    print(\"‚úÖ Created monthly_kpi_summary view successfully!\")\n",
        "    \n",
        "    # Test the view\n",
        "    cursor.execute(\"SELECT * FROM monthly_kpi_summary ORDER BY total_rides DESC LIMIT 3;\")\n",
        "    top_months = cursor.fetchall()\n",
        "    \n",
        "    print(\"üìä Top 3 months by ridership:\")\n",
        "    for row in top_months:\n",
        "        print(f\"   {row[2]} {int(row[0])}: {row[3]} rides, {row[10]}% subscribers, {row[11]}¬∞F avg\")\n",
        "    \n",
        "    cursor.close()\n",
        "    conn.close()\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error creating monthly KPI view: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Created weather_impact_analysis view successfully!\n",
            "üìä Weather impact on ridership:\n",
            "   Mild (Fall): 79704 rides, 10.17 min avg, 61.9¬∞F\n",
            "   Mild (Summer): 55857 rides, 12.95 min avg, 74.9¬∞F\n",
            "   Mild (Spring): 46491 rides, 12.57 min avg, 58.0¬∞F\n",
            "   Hot (Summer): 26585 rides, 12.17 min avg, 83.5¬∞F\n",
            "   Cold (Winter): 17789 rides, 8.67 min avg, 32.4¬∞F\n",
            "   Mild (Winter): 12586 rides, 9.98 min avg, 45.4¬∞F\n",
            "   Hot (Fall): 3081 rides, 13.33 min avg, 84.0¬∞F\n",
            "   Cold (Spring): 2251 rides, 10.33 min avg, 35.3¬∞F\n",
            "   Cold (Fall): 1407 rides, 6.71 min avg, 39.0¬∞F\n",
            "   Hot (Spring): 528 rides, 18.18 min avg, 82.0¬∞F\n"
          ]
        }
      ],
      "source": [
        "# Create weather impact analysis view\n",
        "try:\n",
        "    conn = psycopg2.connect(conn_string)\n",
        "    cursor = conn.cursor()\n",
        "    \n",
        "    # Create view for weather impact analysis\n",
        "    create_weather_impact_view = \"\"\"\n",
        "    CREATE OR REPLACE VIEW weather_impact_analysis AS\n",
        "    SELECT \n",
        "        w.weather_category,\n",
        "        w.season,\n",
        "        COUNT(r.ride_id) as total_rides,\n",
        "        ROUND(AVG(r.trip_duration_minutes), 2) as avg_trip_duration,\n",
        "        ROUND(AVG(w.avg_temp), 1) as avg_temperature,\n",
        "        ROUND(AVG(w.precipitation), 3) as avg_precipitation,\n",
        "        ROUND(AVG(w.avg_wind_speed), 1) as avg_wind_speed,\n",
        "        COUNT(DISTINCT r.start_station_id) as active_stations,\n",
        "        ROUND(COUNT(r.ride_id) * 100.0 / SUM(COUNT(r.ride_id)) OVER(), 2) as percentage_of_rides,\n",
        "        ROUND(AVG(r.age), 1) as avg_rider_age,\n",
        "        COUNT(CASE WHEN r.user_type = 'Subscriber' THEN 1 END) as subscriber_rides,\n",
        "        COUNT(CASE WHEN r.user_type = 'Customer' THEN 1 END) as customer_rides\n",
        "    FROM weather w\n",
        "    JOIN rides r ON w.date = r.date\n",
        "    WHERE w.weather_category IS NOT NULL\n",
        "    GROUP BY w.weather_category, w.season\n",
        "    ORDER BY total_rides DESC;\n",
        "    \"\"\"\n",
        "    \n",
        "    cursor.execute(create_weather_impact_view)\n",
        "    conn.commit()\n",
        "    \n",
        "    print(\"‚úÖ Created weather_impact_analysis view successfully!\")\n",
        "    \n",
        "    # Test the view\n",
        "    cursor.execute(\"SELECT * FROM weather_impact_analysis;\")\n",
        "    weather_impact = cursor.fetchall()\n",
        "    \n",
        "    print(\"üìä Weather impact on ridership:\")\n",
        "    for row in weather_impact:\n",
        "        print(f\"   {row[0]} ({row[1]}): {row[2]} rides, {row[3]} min avg, {row[4]}¬∞F\")\n",
        "    \n",
        "    cursor.close()\n",
        "    conn.close()\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error creating weather impact view: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîç View Documentation and Testing\n",
        "\n",
        "Let's document all the views we've created and test some complex analytics queries.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìã Created Analytics Views:\n",
            "==================================================\n",
            "\n",
            "üîç daily_weather_rides\n",
            "   Purpose: Daily weather-ridership correlation analysis\n",
            "   Use case: Understand how weather affects daily ridership patterns\n",
            "\n",
            "üîç hourly_ridership_patterns\n",
            "   Purpose: Hourly ridership patterns and peak time analysis\n",
            "   Use case: Identify peak hours and optimize bike distribution\n",
            "\n",
            "üîç monthly_kpi_summary\n",
            "   Purpose: Monthly KPI summary with weather correlation\n",
            "   Use case: Monthly business performance tracking\n",
            "\n",
            "üîç station_utilization\n",
            "   Purpose: Station performance and utilization metrics\n",
            "   Use case: Identify high-traffic stations and optimize placement\n",
            "\n",
            "üîç weather_impact_analysis\n",
            "   Purpose: Weather impact on ridership by category\n",
            "   Use case: Understand weather sensitivity for operations planning\n",
            "\n",
            "üîç weekly_ridership_patterns\n",
            "   Purpose: Weekly ridership patterns by day of week\n",
            "   Use case: Understand weekday vs weekend usage patterns\n"
          ]
        }
      ],
      "source": [
        "# List all created views and their purposes\n",
        "try:\n",
        "    conn = psycopg2.connect(conn_string)\n",
        "    cursor = conn.cursor()\n",
        "    \n",
        "    # Get all views in the database\n",
        "    cursor.execute(\"\"\"\n",
        "        SELECT viewname, definition \n",
        "        FROM pg_views \n",
        "        WHERE schemaname = 'public' \n",
        "        ORDER BY viewname;\n",
        "    \"\"\")\n",
        "    \n",
        "    views = cursor.fetchall()\n",
        "    \n",
        "    print(\"üìã Created Analytics Views:\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    for view in views:\n",
        "        print(f\"\\nüîç {view[0]}\")\n",
        "        if 'daily_weather_rides' in view[0]:\n",
        "            print(\"   Purpose: Daily weather-ridership correlation analysis\")\n",
        "            print(\"   Use case: Understand how weather affects daily ridership patterns\")\n",
        "        elif 'hourly_ridership_patterns' in view[0]:\n",
        "            print(\"   Purpose: Hourly ridership patterns and peak time analysis\")\n",
        "            print(\"   Use case: Identify peak hours and optimize bike distribution\")\n",
        "        elif 'weekly_ridership_patterns' in view[0]:\n",
        "            print(\"   Purpose: Weekly ridership patterns by day of week\")\n",
        "            print(\"   Use case: Understand weekday vs weekend usage patterns\")\n",
        "        elif 'station_utilization' in view[0]:\n",
        "            print(\"   Purpose: Station performance and utilization metrics\")\n",
        "            print(\"   Use case: Identify high-traffic stations and optimize placement\")\n",
        "        elif 'monthly_kpi_summary' in view[0]:\n",
        "            print(\"   Purpose: Monthly KPI summary with weather correlation\")\n",
        "            print(\"   Use case: Monthly business performance tracking\")\n",
        "        elif 'weather_impact_analysis' in view[0]:\n",
        "            print(\"   Purpose: Weather impact on ridership by category\")\n",
        "            print(\"   Use case: Understand weather sensitivity for operations planning\")\n",
        "    \n",
        "    cursor.close()\n",
        "    conn.close()\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error listing views: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç Complex Analytics Query Results:\n",
            "Weather Impact on Peak Hour Ridership\n",
            "==================================================\n",
            "   Cold weather at 08:00: 3058 rides (36.15% of Cold rides)\n",
            "   Cold weather at 09:00: 1445 rides (17.08% of Cold rides)\n",
            "   Cold weather at 17:00: 1808 rides (21.37% of Cold rides)\n",
            "   Cold weather at 18:00: 2148 rides (25.39% of Cold rides)\n",
            "   Hot weather at 08:00: 3280 rides (31.23% of Hot rides)\n",
            "   Hot weather at 09:00: 1734 rides (16.51% of Hot rides)\n",
            "   Hot weather at 17:00: 2579 rides (24.56% of Hot rides)\n",
            "   Hot weather at 18:00: 2909 rides (27.70% of Hot rides)\n",
            "   Mild weather at 08:00: 22794 rides (31.93% of Mild rides)\n",
            "   Mild weather at 09:00: 11661 rides (16.33% of Mild rides)\n",
            "   Mild weather at 17:00: 17608 rides (24.66% of Mild rides)\n",
            "   Mild weather at 18:00: 19328 rides (27.07% of Mild rides)\n"
          ]
        }
      ],
      "source": [
        "# Test complex analytics query using multiple views\n",
        "try:\n",
        "    conn = psycopg2.connect(conn_string)\n",
        "    cursor = conn.cursor()\n",
        "    \n",
        "    # Complex query: Weather impact on peak hour ridership\n",
        "    complex_query = \"\"\"\n",
        "    SELECT \n",
        "        w.weather_category,\n",
        "        h.hour_of_day,\n",
        "        COUNT(*) as rides_at_peak_weather,\n",
        "        ROUND(AVG(r.trip_duration_minutes), 2) as avg_duration,\n",
        "        ROUND(COUNT(*) * 100.0 / SUM(COUNT(*)) OVER(PARTITION BY w.weather_category), 2) as percentage_of_weather_rides\n",
        "    FROM rides r\n",
        "    JOIN weather w ON r.date = w.date\n",
        "    JOIN hourly_ridership_patterns h ON r.hour_of_day = h.hour_of_day\n",
        "    WHERE w.weather_category IN ('Hot', 'Cold', 'Mild')\n",
        "    AND h.hour_of_day IN (8, 9, 17, 18)  -- Peak hours\n",
        "    GROUP BY w.weather_category, h.hour_of_day\n",
        "    ORDER BY w.weather_category, h.hour_of_day;\n",
        "    \"\"\"\n",
        "    \n",
        "    cursor.execute(complex_query)\n",
        "    results = cursor.fetchall()\n",
        "    \n",
        "    print(\"üîç Complex Analytics Query Results:\")\n",
        "    print(\"Weather Impact on Peak Hour Ridership\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    for row in results:\n",
        "        print(f\"   {row[0]} weather at {row[1]:02d}:00: {row[2]} rides ({row[4]}% of {row[0]} rides)\")\n",
        "    \n",
        "    cursor.close()\n",
        "    conn.close()\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error executing complex query: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìù Phase 5 Summary\n",
        "\n",
        "### Document Your Analytics Views:\n",
        "1. **Views Created**: \n",
        "   - **6 comprehensive analytics views** for business intelligence\n",
        "   - **Weather-ridership correlation** analysis\n",
        "   - **Time-based patterns** (hourly, weekly, monthly)\n",
        "   - **Station utilization** metrics\n",
        "   - **KPI tracking** and performance monitoring\n",
        "\n",
        "2. **Business Intelligence Capabilities**:\n",
        "   - **Daily weather impact** on ridership patterns\n",
        "   - **Peak hour identification** for operations optimization\n",
        "   - **Station performance** analysis for placement decisions\n",
        "   - **Monthly KPI tracking** with weather correlation\n",
        "   - **Weather sensitivity** analysis for planning\n",
        "\n",
        "3. **Analytics Features**:\n",
        "   - **Complex JOIN queries** across multiple tables\n",
        "   - **Aggregation functions** (COUNT, AVG, SUM, ROUND)\n",
        "   - **Window functions** for percentage calculations\n",
        "   - **CASE statements** for conditional analysis\n",
        "   - **Date/time functions** for temporal analysis\n",
        "\n",
        "4. **View Documentation**:\n",
        "   - [x] daily_weather_rides - Weather-ridership correlation\n",
        "   - [x] hourly_ridership_patterns - Peak time analysis\n",
        "   - [x] weekly_ridership_patterns - Day-of-week patterns\n",
        "   - [x] station_utilization - Station performance metrics\n",
        "   - [x] monthly_kpi_summary - Business performance tracking\n",
        "   - [x] weather_impact_analysis - Weather sensitivity analysis\n",
        "\n",
        "### Business Value Delivered:\n",
        "- **Operational Insights**: Peak hours, station utilization, weather impact\n",
        "- **Strategic Planning**: Monthly trends, seasonal patterns, user behavior\n",
        "- **Performance Monitoring**: KPI tracking, subscriber analysis, efficiency metrics\n",
        "- **Data-Driven Decisions**: Weather-based operations, station optimization\n",
        "\n",
        "### Next Steps:\n",
        "- [x] Complete Phase 5 analytics views\n",
        "- [ ] Move to Phase 6: Portfolio Documentation\n",
        "- [ ] Create comprehensive project write-up\n",
        "- [ ] Document technical decisions and business insights\n",
        "\n",
        "---\n",
        "\n",
        "**Excellent work!** Your analytics views provide comprehensive business intelligence capabilities. The bike rental company now has powerful tools for data-driven decision making!\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Codecademy ML",
      "language": "python",
      "name": "codeacademy"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
